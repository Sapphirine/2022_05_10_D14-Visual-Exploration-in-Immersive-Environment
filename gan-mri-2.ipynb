{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-09T05:44:26.129783Z","iopub.execute_input":"2022-05-09T05:44:26.130526Z","iopub.status.idle":"2022-05-09T05:44:26.171234Z","shell.execute_reply.started":"2022-05-09T05:44:26.130486Z","shell.execute_reply":"2022-05-09T05:44:26.160373Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#The following code is referenced and modefied by Nanashi's GAN introduction. Her code\n# is this (https://www.kaggle.com/code/jesucristo/gan-introduction)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T09:07:04.526080Z","iopub.execute_input":"2022-05-09T09:07:04.526496Z","iopub.status.idle":"2022-05-09T09:07:04.530143Z","shell.execute_reply.started":"2022-05-09T09:07:04.526464Z","shell.execute_reply":"2022-05-09T09:07:04.529422Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:44:33.719960Z","iopub.execute_input":"2022-05-09T05:44:33.720290Z","iopub.status.idle":"2022-05-09T05:44:33.725910Z","shell.execute_reply.started":"2022-05-09T05:44:33.720251Z","shell.execute_reply":"2022-05-09T05:44:33.724908Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import save_image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom tqdm import tqdm_notebook as tqdm\nprint(\"Complete\")","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:44:36.035773Z","iopub.execute_input":"2022-05-09T05:44:36.036462Z","iopub.status.idle":"2022-05-09T05:44:36.044392Z","shell.execute_reply.started":"2022-05-09T05:44:36.036412Z","shell.execute_reply":"2022-05-09T05:44:36.043367Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Display some images for visulization \nPATH = '../input/mritumormri/glioma/'\nimages = os.listdir(PATH)\nprint(f'There are {len(os.listdir(PATH))} pictures of MRI.')\n\nfig, axes = plt.subplots(nrows=4, ncols=4, figsize=(12,10))\n\nfor indx, axis in enumerate(axes.flatten()):\n    rnd_indx = np.random.randint(0, len(os.listdir(PATH)))\n    print(rnd_indx)\n    img = plt.imread(PATH + images[rnd_indx])\n    imgplot = axis.imshow(img)\n    axis.set_title(images[rnd_indx])\n    axis.set_axis_off()\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:44:38.718995Z","iopub.execute_input":"2022-05-09T05:44:38.720064Z","iopub.status.idle":"2022-05-09T05:44:40.386477Z","shell.execute_reply.started":"2022-05-09T05:44:38.720026Z","shell.execute_reply":"2022-05-09T05:44:40.385406Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nimage_size = 64\n\nrandom_transforms = [transforms.ColorJitter(), transforms.RandomRotation(degrees=0)]\ntransform = transforms.Compose([transforms.Resize(64),\n                                transforms.CenterCrop(64),\n                                transforms.RandomHorizontalFlip(p=0.5),\n                                transforms.RandomApply(random_transforms, p=0.2),\n                                transforms.ToTensor()])\n                                #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrain_data = datasets.ImageFolder('../input/mritumormri/', transform=transform)\ntrain_loader = torch.utils.data.DataLoader(train_data, shuffle=True,\n                                           batch_size=batch_size)\n                                          \nimgs, label = next(iter(train_loader))\nimgs = imgs.numpy().transpose(0, 2, 3, 1)\nprint(type(imgs))\nnoise = np. random. normal(0, .1, imgs. shape)\nimgs = imgs + noise\n\nprint(\"complete\")","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:44:46.584485Z","iopub.execute_input":"2022-05-09T05:44:46.584766Z","iopub.status.idle":"2022-05-09T05:44:46.780801Z","shell.execute_reply.started":"2022-05-09T05:44:46.584738Z","shell.execute_reply":"2022-05-09T05:44:46.779677Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    plt.imshow(imgs[i])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:44:52.019497Z","iopub.execute_input":"2022-05-09T05:44:52.019814Z","iopub.status.idle":"2022-05-09T05:44:52.721648Z","shell.execute_reply.started":"2022-05-09T05:44:52.019779Z","shell.execute_reply":"2022-05-09T05:44:52.720915Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def weights_init(m):\n    \"\"\"\n    Takes as input a neural network m that will initialize all its weights.\n    \"\"\"\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:44:55.966170Z","iopub.execute_input":"2022-05-09T05:44:55.967284Z","iopub.status.idle":"2022-05-09T05:44:55.974260Z","shell.execute_reply.started":"2022-05-09T05:44:55.967223Z","shell.execute_reply":"2022-05-09T05:44:55.973217Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Create Generator\nclass G(nn.Module):\n    def __init__(self):\n        # Used to inherit the torch.nn Module\n        super(G, self).__init__()\n        # Meta Module - consists of different layers of Modules\n        self.main = nn.Sequential(\n                nn.ConvTranspose2d(100, 512, 4, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(512),\n                nn.ReLU(True),\n                nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1, bias=False),\n                nn.BatchNorm2d(256),\n                nn.ReLU(True),\n                nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1, bias=False),\n                nn.BatchNorm2d(128),\n                nn.ReLU(True),\n                nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1, bias=False),\n                nn.BatchNorm2d(64),\n                nn.ReLU(True),\n                nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1, bias=False),\n                nn.Tanh()\n                )\n        \n    def forward(self, input):\n        output = self.main(input)\n        return output\n\n# Creating the generator\nnetG = G()\nnetG.apply(weights_init)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:45:01.682946Z","iopub.execute_input":"2022-05-09T05:45:01.683238Z","iopub.status.idle":"2022-05-09T05:45:01.750663Z","shell.execute_reply.started":"2022-05-09T05:45:01.683204Z","shell.execute_reply":"2022-05-09T05:45:01.750066Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Defining the discriminator\nclass D(nn.Module):\n    def __init__(self):\n        super(D, self).__init__()\n        self.main = nn.Sequential(\n                nn.Conv2d(3, 64, 4, stride=2, padding=1, bias=False),\n                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n                nn.Conv2d(64, 128, 4, stride=2, padding=1, bias=False),\n                nn.BatchNorm2d(128),\n                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n                nn.Conv2d(128, 256, 4, stride=2, padding=1, bias=False),\n                nn.BatchNorm2d(256),\n                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n                nn.Conv2d(256, 512, 4, stride=2, padding=1, bias=False),\n                nn.BatchNorm2d(512),\n                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n                nn.Conv2d(512, 1, 4, stride=1, padding=0, bias=False),\n                nn.Sigmoid()\n                )\n        \n    def forward(self, input):\n        output = self.main(input)\n        # .view(-1) = Flattens the output into 1D instead of 2D\n        return output.view(-1)\n    \n    \n# Creating the discriminator\nnetD = D()\nnetD.apply(weights_init)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:45:05.032979Z","iopub.execute_input":"2022-05-09T05:45:05.033834Z","iopub.status.idle":"2022-05-09T05:45:05.091844Z","shell.execute_reply.started":"2022-05-09T05:45:05.033797Z","shell.execute_reply":"2022-05-09T05:45:05.090564Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, nz=128, channels=3):\n        super(Generator, self).__init__()\n        \n        self.nz = nz\n        self.channels = channels\n        \n        def convlayer(n_input, n_output, k_size=4, stride=2, padding=0):\n            block = [\n                nn.ConvTranspose2d(n_input, n_output, kernel_size=k_size, stride=stride, padding=padding, bias=False),\n                nn.BatchNorm2d(n_output),\n                nn.ReLU(inplace=True),\n            ]\n            return block\n\n        self.model = nn.Sequential(\n            *convlayer(self.nz, 1024, 4, 1, 0), # Fully connected layer via convolution.\n            *convlayer(1024, 512, 4, 2, 1),\n            *convlayer(512, 256, 4, 2, 1),\n            *convlayer(256, 128, 4, 2, 1),\n            *convlayer(128, 64, 4, 2, 1),\n            nn.ConvTranspose2d(64, self.channels, 3, 1, 1),\n            nn.Tanh()\n        )\n\n    def forward(self, z):\n        z = z.view(-1, self.nz, 1, 1)\n        img = self.model(z)\n        return img\n\n    \nclass Discriminator(nn.Module):\n    def __init__(self, channels=3):\n        super(Discriminator, self).__init__()\n        \n        self.channels = channels\n\n        def convlayer(n_input, n_output, k_size=4, stride=2, padding=0, bn=False):\n            block = [nn.Conv2d(n_input, n_output, kernel_size=k_size, stride=stride, padding=padding, bias=False)]\n            if bn:\n                block.append(nn.BatchNorm2d(n_output))\n            block.append(nn.LeakyReLU(0.2, inplace=True))\n            return block\n\n        self.model = nn.Sequential(\n            *convlayer(self.channels, 32, 4, 2, 1),\n            *convlayer(32, 64, 4, 2, 1),\n            *convlayer(64, 128, 4, 2, 1, bn=True),\n            *convlayer(128, 256, 4, 2, 1, bn=True),\n            nn.Conv2d(256, 1, 4, 1, 0, bias=False),  # FC with Conv.\n        )\n\n    def forward(self, imgs):\n        logits = self.model(imgs)\n        out = torch.sigmoid(logits)\n    \n        return out.view(-1, 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:45:07.918403Z","iopub.execute_input":"2022-05-09T05:45:07.918689Z","iopub.status.idle":"2022-05-09T05:45:07.932301Z","shell.execute_reply.started":"2022-05-09T05:45:07.918660Z","shell.execute_reply":"2022-05-09T05:45:07.931123Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"!mkdir MRIresults\n!ls","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:45:16.309180Z","iopub.execute_input":"2022-05-09T05:45:16.309967Z","iopub.status.idle":"2022-05-09T05:45:17.971443Z","shell.execute_reply.started":"2022-05-09T05:45:16.309920Z","shell.execute_reply":"2022-05-09T05:45:17.970315Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"EPOCH = 30 # play with me\nLR = 0.001\ncriterion = nn.BCELoss()\noptimizerD = optim.Adam(netD.parameters(), lr=LR, betas=(0.5, 0.999))\noptimizerG = optim.Adam(netG.parameters(), lr=LR, betas=(0.5, 0.999))","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:45:39.702359Z","iopub.execute_input":"2022-05-09T05:45:39.702658Z","iopub.status.idle":"2022-05-09T05:45:39.708779Z","shell.execute_reply.started":"2022-05-09T05:45:39.702624Z","shell.execute_reply":"2022-05-09T05:45:39.708012Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"import numpy\nimport tensorflow as tf\nfor epoch in range(EPOCH):\n    for i, data in enumerate(train_loader, 0):   \n        # 1st Step: Updating the weights of the neural network of the discriminator\n        netD.zero_grad()\n\n                \n        # Training the discriminator with a real image of the dataset\n        real,_ = data\n        input = Variable(real)\n        target = Variable(torch.ones(input.size()[0]))\n        output = netD(input)\n        errD_real = criterion(output, target)\n        \n        # Training the discriminator with a fake image generated by the generator\n        # You can train the dsicrimnator from random noise, or you can train the dscrimnator from the image with Gaussian noise\n        noise = Variable(torch.randn(input.size()[0], 100, 1, 1))\n        #The fake image is from the real image added with Gaussisian noise \n        # The belowing code is for discrimator training from the image with Gaussian noise.\n        #noise=input\n        #noise = noise + (0.1**0.5)*torch.randn(3, 64, 64)\n\n        fake = netG(noise)\n        target = Variable(torch.zeros(input.size()[0]))\n        output = netD(fake.detach())\n        errD_fake = criterion(output, target)\n       \n\n        \n        fake = netG(noise)\n        target = Variable(torch.zeros(input.size()[0]))\n        output = netD(fake.detach())\n        errD_fake = criterion(output, target)\n        \n        # Backpropagating the total error\n        errD = errD_real + errD_fake\n        errD.backward()\n        optimizerD.step()\n        \n        # 2nd Step: Updating the weights of the neural network of the generator\n        netG.zero_grad()\n        target = Variable(torch.ones(input.size()[0]))\n        output = netD(fake)\n        errG = criterion(output, target)\n        errG.backward()\n        optimizerG.step()\n        \n        # 3rd Step: Printing the losses and saving the real images and the generated images of the minibatch every 100 steps\n        print('[%d/%d][%d/%d] Loss_D: %.4f; Loss_G: %.4f' % (epoch, EPOCH, i, len(train_loader), errD.item(), errG.item()))\n        if i % 100 == 0:\n            vutils.save_image(real, '%s/real_samples.png' % \"./MRIresults\", normalize=True)\n            fake = netG(noise)\n            vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % (\"./MRIresults\", epoch), normalize=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:45:42.716861Z","iopub.execute_input":"2022-05-09T05:45:42.717331Z","iopub.status.idle":"2022-05-09T05:52:21.392136Z","shell.execute_reply.started":"2022-05-09T05:45:42.717291Z","shell.execute_reply":"2022-05-09T05:52:21.391214Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nLR_G = 0.001\nLR_D = 0.0005\n\nbeta1 = 0.5\nepochs = 100\n\nreal_label = 0.9\nfake_label = 0\nnz = 128\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"complete\")","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:55:21.976777Z","iopub.execute_input":"2022-05-09T05:55:21.977408Z","iopub.status.idle":"2022-05-09T05:55:21.985207Z","shell.execute_reply.started":"2022-05-09T05:55:21.977358Z","shell.execute_reply":"2022-05-09T05:55:21.984225Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"netG = Generator(nz).to(device)\nnetD = Discriminator().to(device)\n\ncriterion = nn.BCELoss()\n\noptimizerD = optim.Adam(netD.parameters(), lr=LR_D, betas=(beta1, 0.999))\noptimizerG = optim.Adam(netG.parameters(), lr=LR_G, betas=(beta1, 0.999))\n\nfixed_noise = torch.randn(25, nz, 1, 1, device=device)\n\nG_losses = []\nD_losses = []\nepoch_time = []\n\nprint(\"complete\")","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:55:32.031661Z","iopub.execute_input":"2022-05-09T05:55:32.032135Z","iopub.status.idle":"2022-05-09T05:55:32.147007Z","shell.execute_reply.started":"2022-05-09T05:55:32.032102Z","shell.execute_reply":"2022-05-09T05:55:32.145967Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def plot_loss (G_losses, D_losses, epoch):\n    plt.figure(figsize=(10,5))\n    plt.title(\"Generator and Discriminator Loss - EPOCH \"+ str(epoch))\n    plt.plot(G_losses,label=\"G\")\n    plt.plot(D_losses,label=\"D\")\n    plt.xlabel(\"iterations\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:55:43.450845Z","iopub.execute_input":"2022-05-09T05:55:43.451142Z","iopub.status.idle":"2022-05-09T05:55:43.456401Z","shell.execute_reply.started":"2022-05-09T05:55:43.451112Z","shell.execute_reply":"2022-05-09T05:55:43.455551Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"def show_generated_img(n_images=5):\n    sample = []\n    for _ in range(n_images):\n        noise = torch.randn(1, nz, 1, 1, device=device)\n        gen_image = netG(noise).to(\"cpu\").clone().detach().squeeze(0)\n        gen_image = gen_image.numpy().transpose(1, 2, 0)\n        sample.append(gen_image)\n    \n    figure, axes = plt.subplots(1, len(sample), figsize = (64,64))\n    for index, axis in enumerate(axes):\n        axis.axis('off')\n        image_array = sample[index]\n        axis.imshow(image_array)\n        \n    plt.show()\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:55:54.065557Z","iopub.execute_input":"2022-05-09T05:55:54.066214Z","iopub.status.idle":"2022-05-09T05:55:54.072949Z","shell.execute_reply.started":"2022-05-09T05:55:54.066171Z","shell.execute_reply":"2022-05-09T05:55:54.072260Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epochs):\n    \n    start = time.time()\n    for ii, (real_images, train_labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n        ############################\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        # train with real\n        netD.zero_grad()\n        real_images = real_images.to(device)\n        batch_size = real_images.size(0)\n        labels = torch.full((batch_size, 1), real_label, device=device)\n\n        output = netD(real_images)\n        errD_real = criterion(output, labels)\n        errD_real.backward()\n        D_x = output.mean().item()\n\n        # train with fake\n        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n        fake = netG(noise)\n        labels.fill_(fake_label)\n        output = netD(fake.detach())\n        errD_fake = criterion(output, labels)\n        errD_fake.backward()\n        D_G_z1 = output.mean().item()\n        errD = errD_real + errD_fake\n        optimizerD.step()\n\n        ############################\n        # (2) Update G network: maximize log(D(G(z)))\n        ###########################\n        netG.zero_grad()\n        labels.fill_(real_label)  # fake labels are real for generator cost\n        output = netD(fake)\n        errG = criterion(output, labels)\n        errG.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n        \n        # Save Losses for plotting later\n        G_losses.append(errG.item())\n        D_losses.append(errD.item())\n        \n        if (ii+1) % (len(train_loader)//2) == 0:\n            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n                  % (epoch + 1, epochs, ii+1, len(train_loader),\n                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n            \n    plot_loss (G_losses, D_losses, epoch)\n    G_losses = []\n    D_losses = []\n    if epoch % 10 == 0:\n        show_generated_img()\n\n    epoch_time.append(time.time()- start)\n    \n#             valid_image = netG(fixed_noise)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T05:56:10.204254Z","iopub.execute_input":"2022-05-09T05:56:10.205131Z","iopub.status.idle":"2022-05-09T06:28:09.069953Z","shell.execute_reply.started":"2022-05-09T05:56:10.205090Z","shell.execute_reply":"2022-05-09T06:28:09.068565Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"print (\">> average EPOCH duration = \", np.mean(epoch_time))","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:28:47.162702Z","iopub.execute_input":"2022-05-09T06:28:47.163279Z","iopub.status.idle":"2022-05-09T06:28:47.169087Z","shell.execute_reply.started":"2022-05-09T06:28:47.163237Z","shell.execute_reply":"2022-05-09T06:28:47.168168Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"show_generated_img(7)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:28:56.914163Z","iopub.execute_input":"2022-05-09T06:28:56.914856Z","iopub.status.idle":"2022-05-09T06:28:57.618166Z","shell.execute_reply.started":"2022-05-09T06:28:56.914811Z","shell.execute_reply":"2022-05-09T06:28:57.617565Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists('../output_images'):\n    os.mkdir('../output_images')\n    \nim_batch_size = 50\nn_images=10000\n\nfor i_batch in tqdm(range(0, n_images, im_batch_size)):\n    gen_z = torch.randn(im_batch_size, nz, 1, 1, device=device)\n    gen_images = netG(gen_z)\n    images = gen_images.to(\"cpu\").clone().detach()\n    images = images.numpy().transpose(0, 2, 3, 1)\n    for i_image in range(gen_images.size(0)):\n        save_image(gen_images[i_image, :, :, :], os.path.join('../output_images', f'image_{i_batch+i_image:05d}.png'))","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:29:14.195518Z","iopub.execute_input":"2022-05-09T06:29:14.196025Z","iopub.status.idle":"2022-05-09T06:32:56.280309Z","shell.execute_reply.started":"2022-05-09T06:29:14.195989Z","shell.execute_reply":"2022-05-09T06:32:56.279600Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(25, 16))\n# display 10 images results\nfor i, j in enumerate(images[:32]):\n    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n    plt.imshow(j)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:33:01.220354Z","iopub.execute_input":"2022-05-09T06:33:01.220888Z","iopub.status.idle":"2022-05-09T06:33:02.914947Z","shell.execute_reply.started":"2022-05-09T06:33:01.220839Z","shell.execute_reply":"2022-05-09T06:33:02.913926Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('images', 'zip', '../output_images')","metadata":{"execution":{"iopub.status.busy":"2022-05-09T07:22:52.532716Z","iopub.execute_input":"2022-05-09T07:22:52.533936Z","iopub.status.idle":"2022-05-09T07:22:55.978623Z","shell.execute_reply.started":"2022-05-09T07:22:52.533858Z","shell.execute_reply":"2022-05-09T07:22:55.977598Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"torch.save(netG.state_dict(), 'generator.pth')\ntorch.save(netD.state_dict(), 'discriminator.pth')","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:34:14.017424Z","iopub.execute_input":"2022-05-09T06:34:14.017714Z","iopub.status.idle":"2022-05-09T06:34:14.270184Z","shell.execute_reply.started":"2022-05-09T06:34:14.017681Z","shell.execute_reply":"2022-05-09T06:34:14.269341Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working\nfrom IPython.display import FileLink\n#FileLink(r'/kaggle/working/MRIresults/')","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:43:31.673804Z","iopub.execute_input":"2022-05-09T06:43:31.674363Z","iopub.status.idle":"2022-05-09T06:43:31.679511Z","shell.execute_reply.started":"2022-05-09T06:43:31.674327Z","shell.execute_reply":"2022-05-09T06:43:31.678661Z"},"trusted":true},"execution_count":64,"outputs":[]}]}